{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd16937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime,timezone,timedelta\n",
    "import pytz #time zone data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#commented all the #print functions because the api not working in aws deployment when we have #print functions\n",
    "import multiprocessing\n",
    "\n",
    "NO_OF_THREADS = 5\n",
    "MS_TO_KMH = 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b164ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input_boundaries_to_latlong(lat_boundaries,long_boundaries):\n",
    "    \n",
    "    \"\"\"This is the moest updated user input function. This funtion takes the user data in the form of lat long boundry arays\n",
    "    and then returns the point grid varctors of given latitude and longitude boundaries\"\"\"\n",
    "    \n",
    "    box_lat_list, box_long_list = find_box(lat_boundaries,long_boundaries)\n",
    "    \n",
    "    # extract the data from user inputs    \n",
    "    start_lat = max(box_lat_list)\n",
    "    end_lat = min(box_lat_list)\n",
    "    start_long = min(box_long_list)\n",
    "    end_long = max(box_long_list)\n",
    "\n",
    "    separation_meters = 70\n",
    "    factor = 0.001 # for get points same as Qgis\n",
    "    separation_degrees = separation_meters/111000  #One degree of latitude is approximately 111 kilometers\n",
    "    num_of_points_lat = round(((abs(end_lat - start_lat)/factor) + 1))\n",
    "    num_of_points_long = round(((abs(end_long - start_long)/factor) + 1))\n",
    "\n",
    "\n",
    "\n",
    "    latitudes_arr = np.linspace(start_lat,end_lat,num_of_points_lat)\n",
    "    longitudes_arr = np.linspace(start_long,end_long,num_of_points_long)\n",
    "\n",
    "    # create grid points \n",
    "    point_grid = [(lat,long) for lat in latitudes_arr for long in longitudes_arr]\n",
    "    latitudes = np.array([point_grid[i][0] for i in range(len(point_grid))])\n",
    "    longitudes = np.array([point_grid[i][1] for i in range(len(point_grid))])\n",
    "    \n",
    "    # here longitudes_arr array containing the number of points in x direction (columns)\n",
    "    # here latitudes_arr array containing the number of points in ydirection (raws)\n",
    "    \n",
    "    return latitudes,longitudes,len(longitudes_arr),len(latitudes_arr)\n",
    "\n",
    "def temporal_processing_time_parallel(lat_boundaries,long_boundaries,speed_up=4,threads=NO_OF_THREADS,api_speed=60):\n",
    "    \"\"\"this function returns approximation time to download the weather data\"\"\"\n",
    "    latitudes,longitudes,cols, raws = user_input_boundaries_to_latlong(lat_boundaries,long_boundaries)\n",
    "\n",
    "    num_of_points = cols*raws\n",
    "    download_points = round(num_of_points/speed_up)\n",
    "    time_to_batch = round(download_points/threads)\n",
    "    approx_time_mins = 2*round(time_to_batch/api_speed)  # 2  a is experimental value\n",
    "    if approx_time_mins==0:\n",
    "        approx_time_mins=1\n",
    "        \n",
    "    return approx_time_mins\n",
    "\n",
    "def find_box(lat_boundaries,long_boundaries):\n",
    "    \n",
    "    \"\"\"This function takes user boundaries and then finds and plots the square coodinates for convers the entier farm with \n",
    "    user boundaries. using the outputs we can find the max min lat long coordinates\"\"\"\n",
    "    \n",
    "    # to make the enclosed boundry \n",
    "    lat_boundaries[-1] = lat_boundaries[0]\n",
    "    long_boundaries[-1] = long_boundaries[0]\n",
    "    \n",
    "    box_long_list = [min(long_boundaries),max(long_boundaries), max(long_boundaries), min(long_boundaries)]\n",
    "    box_lat_list = [min(lat_boundaries),min(lat_boundaries),  max(lat_boundaries), max(lat_boundaries)]\n",
    "    \n",
    "    #if need to show plots then uncomment\n",
    "    # for plot a complete square\n",
    "    \"\"\"box_long_list_plot = box_long_list.append(box_long_list[0])\n",
    "    box_lat_list_plot = box_lat_list.append(box_lat_list[1])\n",
    "    \n",
    "    #plot the user boundaries and box boundaries\n",
    "    plt.scatter(long_boundaries,lat_boundaries)\n",
    "    plt.scatter(box_long_list,box_lat_list)\n",
    "\n",
    "    plt.plot(long_boundaries,lat_boundaries, 'b')\n",
    "    plt.plot(box_long_list,box_lat_list,'r')\"\"\"\n",
    "    \n",
    "    return box_lat_list,box_long_list\n",
    "\n",
    "def download_weather_data_raw(latitudes,longitudes,cols,api,speed_up=4):\n",
    "    \n",
    "    # this function extract the weather data from api when provide the lat and long arrays (each raw of latitude)\n",
    "    # the speed_up factor  determines that how may weather data values paeted by previous copied value, here it is pasted 3 values (4-1=3) by previous copied value.\n",
    "    # here cols means number of points in a raw\n",
    "    # create a data frame\n",
    "    grid_point_Weather_data = pd.DataFrame(columns=[\"time\",\"longitude\", \"latitude\",\"tempreture\", \"humidity\",\"wind_speed\",\"weather_id\", \"weather_id_group\", \"weather_id_description\", \"sunrise\", \"sunset\"])\n",
    "    srt_time  = datetime.now()\n",
    "    piangil_timezone = pytz.timezone('Australia/Sydney')\n",
    "\n",
    "    for i in range(int(cols/speed_up)): # contralls the amount of the data\n",
    "\n",
    "        srt_time_point  = datetime.now()\n",
    "        #get the lat long coordinates\n",
    "        lat = latitudes[speed_up*i] \n",
    "        long = longitudes[speed_up*i]\n",
    "\n",
    "        #API url\n",
    "        url = \"https://api.openweathermap.org/data/2.5/weather?lat={}&lon={}&appid={}&units=metric\".format(lat,long,api)\n",
    "        ##print(srt_time_point)\n",
    "        ##print(url)\n",
    "\n",
    "        piangil_time = datetime.now(piangil_timezone) #get time in Australia for data set\n",
    "        \n",
    "        #get data form API as json data (here wile loop is used to prevent to SSL erro failers)\n",
    "        loop_though = True\n",
    "        while loop_though:  \n",
    "            try:\n",
    "                res = requests.get(url)\n",
    "                loop_though = False\n",
    "            except:\n",
    "                pass\n",
    "        data = res.json()\n",
    "\n",
    "        # create the data list that we want from the json data \n",
    "        data_vec = [piangil_time,long, lat, data[\"main\"][\"temp\"], data[\"main\"][\"humidity\"], MS_TO_KMH*data[\"wind\"][\"speed\"], data[\"weather\"][0][\"id\"], data[\"weather\"][0][\"main\"], data[\"weather\"][0][\"description\"], unix_to_aus(data[\"sys\"][\"sunrise\"]), unix_to_aus(data[\"sys\"][\"sunset\"])]\n",
    "        data_vec_1 = [piangil_time,longitudes[speed_up*i+1], latitudes[speed_up*i+1], data[\"main\"][\"temp\"], data[\"main\"][\"humidity\"], MS_TO_KMH*data[\"wind\"][\"speed\"], data[\"weather\"][0][\"id\"], data[\"weather\"][0][\"main\"], data[\"weather\"][0][\"description\"], unix_to_aus(data[\"sys\"][\"sunrise\"]), unix_to_aus(data[\"sys\"][\"sunset\"])]\n",
    "        data_vec_2 = [piangil_time,longitudes[speed_up*i+2], latitudes[speed_up*i+2], data[\"main\"][\"temp\"], data[\"main\"][\"humidity\"], MS_TO_KMH*data[\"wind\"][\"speed\"], data[\"weather\"][0][\"id\"], data[\"weather\"][0][\"main\"], data[\"weather\"][0][\"description\"], unix_to_aus(data[\"sys\"][\"sunrise\"]), unix_to_aus(data[\"sys\"][\"sunset\"])]\n",
    "        data_vec_3 = [piangil_time,longitudes[speed_up*i+3], latitudes[speed_up*i+3], data[\"main\"][\"temp\"], data[\"main\"][\"humidity\"], MS_TO_KMH*data[\"wind\"][\"speed\"], data[\"weather\"][0][\"id\"], data[\"weather\"][0][\"main\"], data[\"weather\"][0][\"description\"], unix_to_aus(data[\"sys\"][\"sunrise\"]), unix_to_aus(data[\"sys\"][\"sunset\"])]\n",
    "\n",
    "\n",
    "        #update the data frame\n",
    "        grid_point_Weather_data.loc[speed_up*i] = data_vec\n",
    "        grid_point_Weather_data.loc[speed_up*i+1] = data_vec_1\n",
    "        grid_point_Weather_data.loc[speed_up*i+2] = data_vec_2\n",
    "        grid_point_Weather_data.loc[speed_up*i+3] = data_vec_3\n",
    "\n",
    "        # if the longitudes arr length (or raw length of the map points) can not divide by speed_up then remaining point in the columns should be filled previous values\n",
    "        if(i%((int(cols/speed_up))-1)==0) and (cols%speed_up !=0) and (i!=0):\n",
    "            num = cols%speed_up\n",
    "            for j in range(num):\n",
    "                data_vec_j = [piangil_time,longitudes[speed_up*i+3+(j+1)], latitudes[speed_up*i+3+(j+1)], data[\"main\"][\"temp\"], data[\"main\"][\"humidity\"], MS_TO_KMH*data[\"wind\"][\"speed\"], data[\"weather\"][0][\"id\"], data[\"weather\"][0][\"main\"], data[\"weather\"][0][\"description\"], unix_to_aus(data[\"sys\"][\"sunrise\"]), unix_to_aus(data[\"sys\"][\"sunset\"])]\n",
    "                grid_point_Weather_data.loc[speed_up*i+3+(j+1)] = data_vec_j\n",
    "                #print(f\"this is done when step is equals to {i+1}\")\n",
    "\n",
    "\n",
    "        time.sleep(0.175)\n",
    "        end_time_point  = datetime.now()\n",
    "        #print(f\"step {i+1} is completed! and taken {end_time_point-srt_time_point} time to complete\")\n",
    "\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    total_execution_time = end_time-srt_time\n",
    "    #print(f\"the programe take: {total_execution_time} to complete\")\n",
    "    \n",
    "          \n",
    "    return grid_point_Weather_data\n",
    "\n",
    "\n",
    "def download_weather_data(latitudes,longitudes,cols,raws,api,key,return_dict):\n",
    "    \n",
    "    grid_point_Weather_data = pd.DataFrame(columns=[\"time\",\"longitude\", \"latitude\",\"tempreture\", \"humidity\",\"wind_speed\",\"weather_id\", \"weather_id_group\", \"weather_id_description\", \"sunrise\", \"sunset\"])\n",
    "    \n",
    "    for i in range(raws):\n",
    "        \n",
    "        # selecting each raw of latitude and longitude arrays\n",
    "        lat_arr = latitudes[i*cols:(i+1)*cols]\n",
    "        long_arr = longitudes[i*cols:(i+1)*cols] \n",
    "        \n",
    "        # get weather data for each raw of latitudes and longitudes\n",
    "        first_batch_data = download_weather_data_raw(lat_arr,long_arr,cols,api)\n",
    "        \n",
    "        # combine the pandas dataframe with previoues one\n",
    "        grid_point_Weather_data = pd.concat([grid_point_Weather_data,first_batch_data], axis=0, ignore_index=True)\n",
    "        #print(f\"complete the {i+1} raw data download\")\n",
    "        #print(\"==================\")\n",
    "        #print(\"==================\")\n",
    "    \n",
    "    # set the Id column and charge the raw order\n",
    "    grid_point_Weather_data[\"id\"] = [j+1 for j in range(cols*raws)]\n",
    "    grid_point_Weather_data = grid_point_Weather_data[[\"id\",\"time\",\"longitude\", \"latitude\",\"tempreture\", \"humidity\",\"wind_speed\",\"weather_id\", \"weather_id_group\", \"weather_id_description\", \"sunrise\", \"sunset\"]]\n",
    "    \n",
    "    return_dict[key] = grid_point_Weather_data\n",
    "\n",
    "\n",
    "def unix_to_aus(time):\n",
    "    \n",
    "    \"\"\"this function convert UNIX date time to Austrelia date time and output will be string. This function is called\n",
    "    inside the download_weather_data_raw function \"\"\"\n",
    "    \n",
    "    time_int = int(time) #get integer value\n",
    "    \n",
    "    time_zone = timezone(timedelta(seconds=36000)) # time zone of Austrelia \n",
    "    \n",
    "    aus_time = datetime.fromtimestamp(time_int, tz = time_zone).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    #aus_time = datetime.fromtimestamp(time_int, tz = time_zone)\n",
    "    \n",
    "    return aus_time\n",
    "\n",
    "def lat_long_batches(latitudes,longitudes,cols,raws,threads=NO_OF_THREADS):\n",
    "    \"\"\"This function takes lat long grid points, num of raws and cols and then returns lat long points batches to call parallel api callings\"\"\"\n",
    "    long_batches = []\n",
    "    lat_batches = []\n",
    "    batch_raw = int(raws/threads)+1\n",
    "    batch_range = batch_raw*cols\n",
    "\n",
    "    for i in range(threads):\n",
    "        long_batch = longitudes[i*batch_range:(i+1)*batch_range]\n",
    "        lat_batch = latitudes[i*batch_range:(i+1)*batch_range]\n",
    "\n",
    "        long_batches.append(long_batch)\n",
    "        lat_batches.append(lat_batch)\n",
    "\n",
    "    return lat_batches,long_batches\n",
    "\n",
    "\n",
    "def create_weather_dataset(lat_boundaries,long_boundaries,api_keys):\n",
    "    \"\"\"This is the final function that we need to call to download the weather dataset\"\"\"   \n",
    "    latitudes,longitudes,cols, raws = user_input_boundaries_to_latlong(lat_boundaries,long_boundaries)\n",
    "    lat_batches,long_batches =  lat_long_batches(latitudes,longitudes,cols,raws)\n",
    "            \n",
    "    manager = multiprocessing.Manager()\n",
    "    return_dict = manager.dict() # this dict contains the results of all threads\n",
    "    jobs = [] # this list contains the all threads\n",
    "    \n",
    "    for i in range(NO_OF_THREADS):\n",
    "        p = multiprocessing.Process(target=download_weather_data, args=(lat_batches[i],long_batches[i],cols,int(len(lat_batches[i])/cols),api_keys[i],i, return_dict))\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for proc in jobs:\n",
    "        proc.join()\n",
    "    \n",
    "    result_list = []\n",
    "    for i in range(len(return_dict)):\n",
    "        result_list.append(return_dict[i])\n",
    "        \n",
    "    dataset = pd.concat(result_list)\n",
    "    #preprocess the dataset\n",
    "    dataset.drop([\"id\"], axis=1, inplace=True)\n",
    "    id_col = np.arange(1,len(dataset)+1,1)\n",
    "    dataset[\"id\"] = id_col\n",
    "    dataset.set_index([np.arange(0,len(dataset),1)], inplace=True)\n",
    "        \n",
    "    #dataset.to_csv(\"./results/csv/weather_dataset.csv\", index=False)\n",
    "    return dataset,latitudes,longitudes,cols,raws"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
